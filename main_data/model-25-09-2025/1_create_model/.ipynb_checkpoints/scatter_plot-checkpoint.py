import json
import os
import matplotlib.pyplot as plt
import pandas as pd
from matplotlib.ticker import FuncFormatter
import arff 
from sklearn.model_selection import train_test_split

# ========================================
# ðŸŽ¨ Plotting & Style Configuration
# ========================================

# --- Font Family ---
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']
plt.rcParams['axes.unicode_minus'] = False

# --- Font Sizes ---
FONT_AXIS_LABEL = 20
FONT_TICK_LABEL = 18
FONT_TITLE = 22
FONT_LEGEND = 16

# --- Apply Font Sizes ---
plt.rcParams['axes.labelsize'] = FONT_AXIS_LABEL
plt.rcParams['xtick.labelsize'] = FONT_TICK_LABEL
plt.rcParams['ytick.labelsize'] = FONT_TICK_LABEL
plt.rcParams['axes.titlesize'] = FONT_TITLE
plt.rcParams['legend.fontsize'] = FONT_LEGEND

# --- General Plotting Settings ---
HIGH_RES_DPI = 300
PAPER_FORMAT_DPI = 75
SINGLE_PLOT_FIGSIZE = (12, 8)

# =======================
# ðŸ”§ Configurable Params
# =======================
INPUT_JSON = "log_stats_final_test.json" # <-- à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸„à¸¸à¸“à¹ƒà¸Šà¹‰
TEST_SET_SIZE = 0.2
RANDOM_STATE = 42

# ========================================================
# ðŸ’¾ ARFF File Generation Function (à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¹ƒà¸«à¸¡à¹ˆ)
# ========================================================
def save_dataframe_to_arff(df, output_path, relation_name):
    """
    Saves a pandas DataFrame to an ARFF file.
    """
    # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­ attribute à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ
    attributes = [
        ('target_send_rate', 'NUMERIC'),
        ('sum_size_increase_bytes', 'NUMERIC') # <-- à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­
    ]
    data = df.values.tolist()
    
    arff_data = {
        'relation': relation_name,
        'attributes': attributes,
        'data': data
    }
    
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            arff.dump(arff_data, f)
        print(f"  âœ… ARFF saved: {os.path.basename(output_path)}")
    except Exception as e:
        print(f"  âŒ Error saving ARFF file: {e}")

# ========================================================
# ðŸ“ˆ Plotting Function (à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¹ƒà¸«à¸¡à¹ˆ)
# ========================================================
def generate_split_scatter_plot(df_train, df_test, output_dir, dpi):
    """
    Generates a scatter plot showing both training and testing data.
    """
    os.makedirs(output_dir, exist_ok=True)
    
    fig, ax = plt.subplots(figsize=SINGLE_PLOT_FIGSIZE)
    
    # --- à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹ƒà¸™à¸à¸²à¸£à¸žà¸¥à¹‡à¸­à¸• ---
    ax.scatter(df_train['target_send_rate'], df_train['sum_size_increase_bytes'], 
               alpha=0.7, s=50, color='blue', label='Train Set')
    ax.scatter(df_test['target_send_rate'], df_test['sum_size_increase_bytes'], 
               alpha=0.7, s=50, color='red', label='Test Set')
    
    # --- à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­à¹à¸à¸™ ---
    ax.set_xlabel("Target Send Rate (msg/s)")
    ax.set_ylabel("Sum of Size Increase (Bytes)") # <-- à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­
    ax.grid(True, which='both', linestyle='--', linewidth=0.5)
    ax.legend()
    
    ax.get_yaxis().set_major_formatter(
        FuncFormatter(lambda y, p: format(int(y), ','))
    )
    plt.xticks(rotation=45)
    
    output_path = os.path.join(output_dir, "scatter_rate_vs_size_increase_split.png")
    fig.savefig(output_path, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    print(f"ðŸ“ˆ Scatter plot saved to '{os.path.basename(output_dir)}/' (DPI={dpi})")

# =======================
# ðŸ”§ Main (à¸•à¸£à¸£à¸à¸°à¹ƒà¸«à¸¡à¹ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”)
# =======================
def main():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    json_path = os.path.join(script_dir, INPUT_JSON)
    if not os.path.exists(json_path):
        print(f"âŒ Error: Input file not found at {json_path}"); return

    with open(json_path, "r", encoding="utf-8") as f: data = json.load(f)

    # --- âœ¨ à¸•à¸£à¸£à¸à¸°à¹ƒà¸«à¸¡à¹ˆà¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ ---
    processed_records = []
    # à¸§à¸™à¸¥à¸¹à¸›à¹€à¸žà¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸£à¸²à¸¢à¸à¸²à¸£à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™ (i) à¸à¸±à¸šà¸£à¸²à¸¢à¸à¸²à¸£à¸–à¸±à¸”à¹„à¸› (i+1)
    for i in range(len(data) - 1):
        current_record = data[i]
        next_record = data[i+1]

        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² target_send_rate à¸‚à¸­à¸‡à¸ªà¸­à¸‡à¸£à¸²à¸¢à¸à¸²à¸£à¸—à¸µà¹ˆà¸•à¸´à¸”à¸à¸±à¸™à¹€à¸—à¹ˆà¸²à¸à¸±à¸™à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
        if current_record.get("target_send_rate") == next_record.get("target_send_rate"):
            
            # à¸”à¸¶à¸‡à¸„à¹ˆà¸² send_rate (à¹€à¸›à¹‡à¸™ feature)
            send_rate = current_record.get("target_send_rate")
            
            # à¸„à¸³à¸™à¸§à¸“à¸œà¸¥à¸£à¸§à¸¡ size_increase_bytes (à¹€à¸›à¹‡à¸™ target)
            sum_increase = current_record.get("size_increase_bytes", 0) + next_record.get("size_increase_bytes", 0)
            
            # à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¹‰à¸§à¹€à¸‚à¹‰à¸²à¹„à¸›à¹ƒà¸™à¸¥à¸´à¸ªà¸•à¹Œ
            processed_records.append({
                "target_send_rate": send_rate,
                "sum_size_increase_bytes": sum_increase
            })

    if not processed_records:
        print("âŒ Error: No adjacent records with matching 'target_send_rate' were found."); return
        
    df_processed = pd.DataFrame(processed_records)
    # à¸­à¸²à¸ˆà¸¡à¸µ send_rate à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸ˆà¸²à¸ repetition à¸­à¸·à¹ˆà¸™à¹† à¹€à¸£à¸²à¸ˆà¸°à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸„à¹ˆà¸²à¹€à¸žà¸·à¹ˆà¸­à¸¥à¸”à¸„à¸§à¸²à¸¡à¸‹à¹‰à¸³à¸‹à¹‰à¸­à¸™
    df_final = df_processed.groupby('target_send_rate')['sum_size_increase_bytes'].mean().reset_index()

    print(f"ðŸ“Š Found {len(data)} records in total.")
    print(f"âš– Processed and aggregated into {len(df_final)} unique data points.")

    # --- ðŸ“‚ à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Train/Test ---
    df_train, df_test = train_test_split(df_final, test_size=TEST_SET_SIZE, random_state=RANDOM_STATE)
    print(f" partitioning Train set size: {len(df_train)}, Test set size: {len(df_test)}")

    # --- ðŸ’¾ à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ ARFF à¸ªà¸³à¸«à¸£à¸±à¸š Train à¹à¸¥à¸° Test ---
    print("\n--- Exporting ARFF Datasets ---")
    save_dataframe_to_arff(df_train, os.path.join(script_dir, "rate_vs_increase_train.arff"), "rate_vs_increase_training")
    save_dataframe_to_arff(df_test, os.path.join(script_dir, "rate_vs_increase_test.arff"), "rate_vs_increase_testing")
    
    # --- ðŸ–¼ï¸ à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸—à¸µà¹ˆà¹à¸ªà¸”à¸‡à¸œà¸¥à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ ---
    print("\n--- Generating Scatter Plots ---")
    generate_split_scatter_plot(df_train, df_test, os.path.join(script_dir, "plots_send_rate_high_res"), HIGH_RES_DPI)
    generate_split_scatter_plot(df_train, df_test, os.path.join(script_dir, "plots_send_rate_small"), PAPER_FORMAT_DPI)

    print("\nâœ… All tasks completed successfully.")

if __name__ == "__main__":
    main()